{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### This function takes a filename as a parameter and reads the file line by line.\n",
    "### The file provided to us contains row of data in each line\n",
    "### The values in each line are comma separated which are column values\n",
    "### The function returns the matrix containing data\n",
    "\n",
    "def load_from_csv(filename):\n",
    "\n",
    "    ### Create an empty data matrix to contain all the data\n",
    "    data=[]\n",
    "    with open(filename,'r') as f:\n",
    "\n",
    "        ### Read the data line by line\n",
    "        rows=f.readlines()\n",
    "        for row in rows:\n",
    "\n",
    "            ### Get list of column values in each row by splitting it by ,\n",
    "            columns=row.split(\",\")\n",
    "\n",
    "            ### Reading file defaults to string data type so we need to convert the values to integer\n",
    "            columns=[int(x) for x in columns]\n",
    "\n",
    "            ### Append the row data array to all data array\n",
    "            data.append(columns)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### This function takes two lists as parameter\n",
    "### This function computes euclidean distance between the two lists\n",
    "def get_distance(p1,p2):\n",
    "    ### Using list comprehension subtract consecutive values from both lists, square the result and sum all the squares.\n",
    "    ### Finally take the square root of sum and return it as euclidean distance\n",
    "    ### Zip function allows working with two lists of same length at the same time\n",
    "    return math.sqrt(sum([(x-y)**2 for x,y in zip(p1,p2)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### This function computes the euclidean distance of a column in matrix.\n",
    "### This function takes two parameters a matrix and column number\n",
    "def get_standard_deviation(mat,col):\n",
    "    ### Get all values of a column in matrix in single list\n",
    "    column=[row[col] for row in mat]\n",
    "\n",
    "    ### Compute the mean of the column values list\n",
    "    column_mean=sum(column)/len(column)\n",
    "\n",
    "    ### Compute the standard deviation by subtracting mean from each value of column, take the square of difference, sum all the\n",
    "    ### squares and devide the sum by total number of values in column. Finally take the square root and return as standdard deviation\n",
    "    return math.sqrt(sum([(x-column_mean)**2 for x in column])/len(column))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### This function takes a single matrix as parameter\n",
    "### This function returns the standardised version of the matrix\n",
    "def get_standardised_matrix(mat):\n",
    "\n",
    "    ### Get all the values of different columns in big array\n",
    "    columns=[]\n",
    "    n_cols=len(mat[0])\n",
    "    for i in range(n_cols):\n",
    "        columns.append([row[i] for row in mat])\n",
    "\n",
    "    ### Compute mean of all the columns\n",
    "    columns_mean=[sum(column)/len(column) for column in columns]\n",
    "\n",
    "    ### Compute standard deviation of all the columns\n",
    "    columns_std=[get_standard_deviation(mat,j) for j in range(n_cols)]\n",
    "\n",
    "\n",
    "    ### Compute the standardised values in each column and create a new standardised column\n",
    "    standardised_cols=[]\n",
    "    for i,column in enumerate(columns):\n",
    "        mean=columns_mean[i]\n",
    "        std=columns_std[i]\n",
    "\n",
    "        new_col=[(x-mean)/std for x in column]\n",
    "        standardised_cols.append(new_col)\n",
    "\n",
    "    ### Since we have the column values horizontally now in the big matrix, taking transpose of standardised column matrix\n",
    "    ### generates the standardised version of the input matrix\n",
    "    return list(map(list, zip(*standardised_cols)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### This function takes a row of data, learning data matrix, learning data labels and integer (k) as parameter\n",
    "### It returns k labels from learning data labels where learning data has the shortest distance with the input row\n",
    "def get_k_nearest_labels(row,lr_data,lr_labels,k):\n",
    "    ### It computes the distance of row of data with all rows of learning data\n",
    "\n",
    "    distances=[get_distance(row,lr_row) for lr_row in lr_data]\n",
    "\n",
    "    ### It sorts the distances and sorted indices as output\n",
    "\n",
    "    sorted_rows_idx=sorted(range(len(distances)),key=distances.__getitem__)\n",
    "\n",
    "    ### It keeps only the first k values in sorted distance ids array\n",
    "\n",
    "    k_rows=sorted_rows_idx[:k]\n",
    "\n",
    "    ### Returns the labels specified in indices at learning data labels\n",
    "    return [lr_labels[i] for i in k_rows]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### This function computes the mode i.e. most frequent label/class in an array (returned by k nearest labels)\n",
    "### This function takes k labels array as input\n",
    "### This function returns the most frequent label in array\n",
    "def get_mode(knn_labels):\n",
    "\n",
    "    ### Create a dictionary to save frequency of all labels\n",
    "    labels_freq={}\n",
    "    for l in knn_labels:\n",
    "        if(l[0] not in labels_freq):\n",
    "            labels_freq[l[0]]=0\n",
    "        labels_freq[l[0]]+=1\n",
    "\n",
    "    ### Find the key in dictionary with maximum count\n",
    "    mode=None\n",
    "    mode_freq=0\n",
    "    for x in labels_freq:\n",
    "        if(labels_freq[x]>mode_freq):\n",
    "            mode_freq=labels_freq[x]\n",
    "            mode=x\n",
    "    ### Return the key as the mode\n",
    "    return [mode]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### This function takes four parameters data, learning dara, learning data labels and an integer (k)\n",
    "### The function return the predicted labels for each row in the data\n",
    "def classify(data,lr_data,lr_labels,k):\n",
    "    result=[]\n",
    "    for row in data:\n",
    "        ### Get k nearest labels for each row in data as shown above\n",
    "        knn_labels=get_k_nearest_labels(row,lr_data,lr_labels,k)\n",
    "\n",
    "        ### Get the mode from knn labels and save it as predicted label\n",
    "        pred=get_mode(knn_labels)\n",
    "        result.append(pred)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### This function takes two parameters correct labels and predicted labels\n",
    "### This function returns the percentage of accuracy\n",
    "def accuracy(correct_labels,pred_labels):\n",
    "\n",
    "    ### Create an array of truth values by comparing the consecutive values in both lists\n",
    "    comparison=[x==y for x,y in zip(correct_labels,pred_labels)]\n",
    "\n",
    "    ### Return the accuracy percentage\n",
    "    return (sum(comparison)/len(comparison))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### This function loads all the data files\n",
    "### Standardises the data and learning data\n",
    "### For a range of k values check the accuracy of knn.\n",
    "def run_tests(data,learning_data,learning_data_labels,correct_data_labels):\n",
    "\n",
    "    ### Load data from files\n",
    "    data=load_from_csv(data)\n",
    "    lr_data=load_from_csv(learning_data)\n",
    "    lr_labels=load_from_csv(learning_data_labels)\n",
    "    data_labels=load_from_csv(correct_data_labels)\n",
    "\n",
    "\n",
    "\n",
    "    ### Standardise the data\n",
    "    std_data=get_standardised_matrix(data)\n",
    "    std_lr_data=get_standardised_matrix(lr_data)\n",
    "\n",
    "    ### Different values of k\n",
    "    k_arr=[x for x in range(3,16)]\n",
    "\n",
    "    ### Accuracy Comparison\n",
    "    for k in k_arr:\n",
    "        pred=classify(std_data,std_lr_data,lr_labels,k)\n",
    "        acc=accuracy(data_labels,pred)\n",
    "        print(\"k= \",end=\"\")\n",
    "        print(k,end=\", \")\n",
    "        print(\"Accuracy = \"+str(round(acc,2))+\" %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k= 3, Accuracy = 95.0 %\n",
      "k= 4, Accuracy = 95.0 %\n",
      "k= 5, Accuracy = 95.71 %\n",
      "k= 6, Accuracy = 96.43 %\n",
      "k= 7, Accuracy = 94.29 %\n",
      "k= 8, Accuracy = 96.43 %\n",
      "k= 9, Accuracy = 95.71 %\n",
      "k= 10, Accuracy = 95.71 %\n",
      "k= 11, Accuracy = 95.71 %\n",
      "k= 12, Accuracy = 95.71 %\n",
      "k= 13, Accuracy = 95.71 %\n",
      "k= 14, Accuracy = 95.71 %\n",
      "k= 15, Accuracy = 95.0 %\n"
     ]
    }
   ],
   "source": [
    "run_tests(data=\"Data.csv\",learning_data='Learning_Data.csv',learning_data_labels='Learning_Data_Labels.csv',correct_data_labels='Correct_Data_Labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
